## I'm [Orr Zohar](https://orrzohar.github.io) ðŸ‘‹

My research focuses on **Large Multi-Modal Models**, especially Large Image/Video + Langauge models, with the hope of pushing these models to be capable of evaluating the quality of actions in video. Recent relevant work:



- <img src="https://github.com/user-attachments/assets/d12dcb46-4833-48ba-9c53-ffac0f623e31" alt="Astronaut Helmet" width="25"> [Apollo](https://apollo-lmms.github.io) coming soon..
- ðŸ’« [Video-STAR](https://arxiv.org/abs/2407.06189): Introduced a method that allows the utilization of any labeled video dataset for instruction tuning. 
- ðŸ¤– [VideoAgent](https://arxiv.org/abs/2403.10517): A novel agent-based system that utilizes a large language model to iteratively identify and compile crucial information from long-form videos
<!--
Currently, I am a PhD student at [MARVL](https://marvl.stanford.edu/), Stanford, and advised by [Prof. Serena Yeung-Levy](https://ai.stanford.edu/~syyeung/).

**orrzohar/orrzohar** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
